# 의료 상담 요약 AI 시스템 - 벤치마크 리포트

## 📊 Executive Summary

의사-환자 대화를 자동으로 분석하여 구조화된 상담 요약 노트를 생성하는 AI 시스템입니다.
한국 의료진 국가시험 데이터셋(KorMedMCQA) 기반 RAG를 활용하여 정확하고 전문적인 의료 요약을 제공합니다.

**핵심 발견사항:**
- ✅ **최적 모델**: GPT-OSS:20B (성공률 100%, 응답속도 24.5초, TPS 18.5)
- ⚡ **최고 속도**: Gemma3:12B (15.2초, TPS 22.3)
- ⚠️ **주의 모델**: Solar (성공률 66.7%, 프로덕션 사용 부적합)

---

## 🏆 모델별 성능 순위

### 종합 평가 (권장도 순)

| 순위 | 모델 | 성공률 | 평균 응답시간 | TPS | 메모리 | 종합 평가 |
|:---:|:---|:---:|:---:|:---:|:---:|:---|
| 🥇 | **GPT-OSS:20B** | ✅ 100% | 24.5초 | 18.5 | 26.4GB | **프로덕션 권장** - 안정성과 성능의 최적 균형 |
| 🥈 | **Gemma3:12B** | ✅ 100% | 15.2초 | 22.3 | 32.2GB | 속도 중시 환경 적합 |
| 🥉 | **Qwen3:8B** | ✅ 100% | 37.8초 | 12.2 | 35.0GB | 리소스 제약 환경 |
| 4 | Gemma3:27B | ✅ 100% | 35.3초 | 8.4 | 36.1GB | 대규모 모델, 속도 대비 성능 미흡 |
| 5 | Qwen3:30B | ✅ 100% | 87.0초 | 6.4 | 30.1GB | 느린 응답속도 |
| ❌ | Solar | ⚠️ 66.7% | 8.5초 | 16.2 | 17.5GB | **사용 비권장** - 낮은 성공률 |

---

## 📈 상세 성능 분석

### 1. 응답 시간 분석

```
빠름 ← ─────────────────────────────────────────────────── → 느림
Solar(8.5s) < Gemma3:12B(15.2s) < GPT-OSS:20B(24.5s) < Gemma3:27B(35.3s) < Qwen3:8B(37.8s) < Qwen3:30B(87.0s)
```

**주요 인사이트:**
- Solar가 가장 빠르지만 33.3% 실패율로 실용성 없음
- Gemma3:12B가 100% 성공률 모델 중 가장 빠름
- 30B 급 대형 모델들의 속도가 현저히 느림

### 2. 처리량 (Tokens Per Second)

| 모델 | 평균 TPS | 최대 TPS | 일관성 |
|:---|:---:|:---:|:---|
| **Gemma3:12B** | 22.3 | 24.8 | 🟢 높음 |
| **GPT-OSS:20B** | 18.5 | 19.8 | 🟢 높음 |
| Solar | 16.2 | 17.4 | 🟡 중간 |
| Qwen3:8B | 12.2 | 15.6 | 🟡 중간 |
| Gemma3:27B | 8.4 | 10.7 | 🔴 낮음 |
| Qwen3:30B | 6.4 | 7.1 | 🔴 낮음 |

### 3. 메모리 사용량

```
효율적 ← ───────────────────────────────────────── → 비효율적
Solar(17.5GB) < GPT-OSS:20B(26.4GB) < Qwen3:30B(30.1GB) < Gemma3:12B(32.2GB) < Qwen3:8B(35.0GB) < Gemma3:27B(36.1GB)
```

**메모리 효율성 분석:**
- Solar: 가장 적은 메모리 사용 (17.5GB)
- GPT-OSS:20B: 성능 대비 효율적 (26.4GB)
- 의외로 8B 모델들이 30B 모델보다 더 많은 메모리 사용

### 4. CPU 사용률

| 모델 | Python CPU | Ollama CPU | 총 CPU 부하 |
|:---|:---:|:---:|:---|
| Solar | 1.4% | 2.6% | 🟢 매우 낮음 |
| Qwen3:8B | 1.3% | 3.9% | 🟢 낮음 |
| Qwen3:30B | 1.5% | 6.6% | 🟡 중간 |
| Gemma3:12B | 1.3% | 8.7% | 🟡 중간 |
| Gemma3:27B | 0.7% | 11.4% | 🟡 중간 |
| **GPT-OSS:20B** | 2.8% | 24.6% | 🔴 높음 |

### 5. 하이브리드 RAG vs 기존 RAG

| 측정 항목 | 기존 RAG | 하이브리드 RAG | 개선율 |
|:---|:---:|:---:|:---|
| 검색 정확도 | 72% | 85% | +18% |
| 약물명 매칭 | 65% | 92% | +42% |
| 응답 시간 | 2.3초 | 1.8초 | -22% |
| 맥락 이해 | 78% | 83% | +6% |

---

## 💡 실제 테스트 결과

### 성공 사례: GPT-OSS:20B의 상담 요약

**입력 대화:**
```
의사: 안녕하세요. 어떤 증상으로 오셨나요?
환자: 3일 전부터 기침이 심하고 열이 나요.
의사: 열은 몇 도까지 올라갔나요?
환자: 어제 저녁에 38.5도까지 올라갔어요.
의사: 가래는 나오나요?
환자: 네, 노란색 가래가 나와요.
의사: 청진 결과 폐에 수포음이 들립니다. 폐렴이 의심되니 흉부 X-ray를 찍어보겠습니다.
```

**생성된 요약:**
```markdown
**주호소 (Chief Complaint)**
3일 전부터 기침과 발열이 지속되며, 노란색 가래가 동반됨

**현병력 (Present Illness)**
- 3일 전: 기침 시작, 열 발생
- 어제 저녁: 체온 38.5°C까지 상승
- 현재: 지속적인 기침, 노란색 가래

**평가 (Assessment)**
- 주요 진단: 폐렴 (청진 시 수포음)
- 감별 진단: 급성 기관지염, 상기도 감염

**계획 (Plan)**
1. 처방 및 치료
   - 항생제: 아목시실린 875mg PO BID x 7일
   - 해열제: 아세트아미노펜 500mg PRN
2. 추가 검사
   - 흉부 X-ray (진행 중)
   - 필요 시 혈액검사 (CBC, CRP)
3. 생활 습관 권고
   - 충분한 수분 섭취 (하루 2L 이상)
   - 휴식

**추적 관찰 (Follow-up)**
- 48-72시간 내 재방문
- 호흡곤란 악화, 39°C 이상 고열 시 즉시 내원
```

### 실패 사례: Solar의 JSON 파싱 오류

```
Error: JSON parsing failed - 불완전한 응답 구조
Success Rate: 66.7% (1/3 성공)
```

---

## 🔬 프롬프트 최적화 실험 결과

### GPT-OSS:20B 모델 프롬프트 전략 비교

| 프롬프트 전략 | 진단 정확도 | JSON 파싱 | 실행 시간 | 결과 품질 | 권장 여부 |
|:---|:---:|:---:|:---:|:---|:---:|
| **기본 (Simple)** | 100% | ✅ 정상 | 24.5초 | 상세하고 정확 | ✅ **권장** |
| Chain-of-Thought | 0% | ❌ 실패 | 17초 | 진단 누락 | ❌ |
| Few-shot (3예시) | 60% | ⚠️ 부분 실패 | 24초 | 텍스트 깨짐 | ❌ |
| Medical Domain | 16% | ❌ 실패 | 25초 | 불완전 | ❌ |
| Role-based | 50% | ⚠️ 불안정 | 23초 | 일관성 없음 | ❌ |

**💡 핵심 교훈:** 
- GPT-OSS:20B는 복잡한 프롬프트보다 **단순명료한 지시**에서 최고 성능 발휘
- "더 복잡한 프롬프트 = 더 나은 성능"이라는 가정은 틀렸음

---

## 🛠️ 시스템 구조 및 기술 스택

### 주요 기능

1. **의사-환자 대화 분석**
   - 실시간 대화 내용 분석 및 핵심 정보 추출
   - 화자 구분 및 발화 의도 파악
   - 의학적 개체 인식 (NER): 증상, 질병, 약물, 검사

2. **자동 상담 요약**
   - 구조화된 노트 생성 (주호소, 현병력, 평가, 계획, 추적 관찰)
   - 스트리밍 출력으로 실시간 요약 생성
   - 신뢰도 점수 제공

3. **하이브리드 RAG 시스템**
   - BM25 + Dense 검색 결합
   - 의학 도메인 특화 토크나이저
   - ICD-10 질병 코드 매칭

### 기술 스택

| 구분 | 기술 | 설명 |
|:---|:---|:---|
| **LLM** | GPT-OSS 20B / Solar | Ollama 로컬 실행, 한국어 최적화 |
| **Vector DB** | ChromaDB | 의학 문서 벡터 저장 및 검색 |
| **Embedding** | jhgan/ko-sroberta-multitask | 한국어 특화 임베딩 모델 |
| **검색 알고리즘** | BM25 + Dense Retrieval | 하이브리드 검색 전략 |
| **Framework** | LangChain | LLM 오케스트레이션 |
| **데이터셋** | KorMedMCQA | 한국 의료진 국가시험 7,469개 문제 |

### 프로젝트 구조 (2025.08.11 개선)

```
doctor-note/
├── src/models/
│   ├── benchmark/          # 벤치마크 모듈
│   │   └── benchmark_runner.py
│   ├── rag/                # RAG 시스템 모듈
│   │   ├── medical_rag_system.py
│   │   └── hybrid_rag_system.py
│   └── summarizer/         # 요약 시스템 모듈
│       └── dialogue_summarizer.py
├── tests/
│   └── run_all_benchmarks.py  # 전체 모델 벤치마크
└── benchmark_results/      # 벤치마크 결과 저장
```

---

## 🚀 권장사항 및 로드맵

### 즉시 적용 가능한 개선사항

1. **프로덕션 배포 전략**
   - Primary: GPT-OSS:20B (안정성 우선)
   - Secondary: Gemma3:12B (속도 우선)
   - Solar 모델 제거

2. **성능 최적화**
   - 응답 캐싱 도입 (Redis)
   - 모델 Quantization 적용 (GGUF Q4_0)
   - 배치 처리 구현

3. **모니터링 강화**
   - 실시간 성공률 모니터링
   - 응답시간 P95, P99 알람 설정
   - 메모리 사용량 임계치 설정

### 개발 로드맵

#### ✅ 완료된 기능 (Phase 1)
- [x] 기본 RAG 시스템 구현
- [x] 하이브리드 검색 (BM25 + Dense)
- [x] 의학 도메인 토크나이저
- [x] 벤치마크 시스템
- [x] 프로토타입 의학 용어 사전 (150개 용어)
- [x] 프로토타입 ICD-10 코드 (80개 주요 질병)

#### 🚧 진행 중 (Phase 2 - AWS 배포)

| 작업 | 기간 | 상세 내용 |
|:---|:---|:---|
| **컨테이너화** | 1-2주 | Ollama Docker 컨테이너화, AWS ECS 배포 |
| **데이터베이스** | 3일 | ChromaDB 컨테이너화, S3 모델 스토리지 |
| **모니터링** | 1주 | CloudWatch 설정, 성능 최적화 |

#### 📋 계획 중 (Phase 3-4)

| 단계 | 기간 | 주요 작업 |
|:---|:---|:---|
| Phase 3 | 1-2개월 | FastAPI 백엔드, 웹 대시보드, 모바일 지원 |
| Phase 4 | 3개월+ | KOSTOM/KCD-8 통합, EMR/PACS 연동, 보험 청구 자동화 |

---

## 🔧 설치 및 사용 방법

### 빠른 시작

```bash
# 1. 저장소 클론
git clone https://github.com/yourusername/doctor-note.git
cd doctor-note

# 2. 가상환경 설정
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 3. Ollama 모델 설치
ollama pull gpt-oss:20b  # 권장 모델
ollama serve

# 4. 초기 데이터 설정
python main.py --mode setup

# 5. 대화 요약 실행
python main.py --mode summarize --dialogue_file data/sample_dialogues.json
```

### 벤치마크 실행

```bash
# 단일 모델 벤치마크
python main.py --mode benchmark --test_file data/sample_dialogues.json

# 전체 모델 비교
python tests/run_all_benchmarks.py
```

---

## ⚠️ 주의사항

**의료 면책 조항**
- 이 시스템은 의료 전문가의 보조 도구로 설계되었습니다
- 실제 진단이나 치료 결정은 반드시 자격을 갖춘 의료진이 수행해야 합니다
- 생성된 요약은 참고용이며, 의학적 조언으로 간주되어서는 안 됩니다

**데이터 관련 안내**
- 현재 의학 용어 사전과 ICD-10 코드는 프로토타입 버전입니다
- 실제 서비스를 위해서는 공인된 의학 데이터베이스 라이선스가 필요합니다

---

## 📝 테스트 환경

- **하드웨어**: macOS Darwin 24.6.0, 16GB+ RAM
- **소프트웨어**: Python 3.10+, Ollama v0.3.x
- **데이터셋**: 한국 의료진 국가시험 데이터셋 (KorMedMCQA)
- **테스트 일자**: 2025년 8월 10일
- **테스트 케이스**: 3개 대화 시나리오 (감기, 두통, 복통)

---

## 🔗 관련 리소스

- [프로젝트 GitHub](https://github.com/yourusername/doctor-note)
- [상세 벤치마크 데이터](/benchmark_results/)
- [KorMedMCQA 데이터셋](https://huggingface.co/datasets/sean0042/KorMedMCQA)
- [한국어 임베딩 모델](https://huggingface.co/jhgan/ko-sroberta-multitask)

---

**작성자**: AI Engineering Team  
**최종 수정**: 2025.08.11  
**버전**: 1.0.1 (통합본)  
**상태**: Active Development