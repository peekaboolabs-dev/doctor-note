# llama.cpp 서버 사용 설정

# LLM 타입 설정
LLM_TYPE=llamacpp_server

# 모델명 (llama.cpp 서버용)
LLM_MODEL=gpt-oss:20b

# llama.cpp 서버 설정
LLAMA_SERVER_HOST=localhost
LLAMA_SERVER_PORT=8080

# LLM 공통 설정
LLM_TEMPERATURE=0.3
LLM_TOP_P=0.9
LLM_MAX_TOKENS=2048
LLM_STREAMING=true

# 임베딩 모델 (RAG용)
EMBEDDING_MODEL=jhgan/ko-sroberta-multitask

# ChromaDB 설정
CHROMA_PERSIST_DIR=data/embeddings/chroma_medical_db
CHUNK_SIZE=1000
CHUNK_OVERLAP=100
COLLECTION_NAME=korean_medical_qa
BATCH_SIZE=500

# 로깅
LOG_LEVEL=INFO
